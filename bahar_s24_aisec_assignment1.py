# -*- coding: utf-8 -*-
"""bahar_s24-aisec-assignment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/barghavanii/812e022fa4830fcbce7e23eabaeaec4c/bahar_s24-aisec-assignment1.ipynb

### Assignment 1: Feature Engineering for Spam Classification

**Objective:**
Enhance the performance of the spam text message classifier by experimenting with feature engineering techniques. Your task is to compare the effectiveness of different feature representations and their impact on the classifier's performance.

**Instructions:**
1. **Count-Based Features:** Start with the CountVectorizer implementation from the tutorial as your baseline model.
2. **TF-IDF Transformation:**
   - Implement a version of the classifier that uses `TfidfVectorizer` for feature extraction. Analyze how TF-IDF features affect the model's accuracy, precision, recall, and F1 score compared to count-based features. For a one-page description of TF-IDF, [see this reference](https://tfidf.com/).
3. **N-grams:**
   - N-grams are an essential feature extraction technique in natural language processing that capture sequences of 'n' items from text, providing context that individual words (unigrams) alone cannot. By considering contiguous sequences of words, n-grams (where 'n' can be 2 for bi-grams, 3 for tri-grams, etc.) incorporate local word order and can significantly enhance the understanding of text semantics. For instance, in the sentence "The quick brown fox jumps", bi-grams would be sequences like "The quick" and "quick brown", capturing more contextual information than unigrams such as "quick", "brown". This additional context can be particularly valuable in tasks like spam detection, where specific word sequences may strongly indicate spam content. By adjusting the `ngram_range` parameter in text vectorization tools like `CountVectorizer` or `TfidfVectorizer`, one can experiment with the inclusion of n-grams to observe their impact on model performance, potentially improving the detection capabilities of classifiers by leveraging the richer linguistic context n-grams provide.
   -- Implement another version of the classifier that includes bi-grams or tri-grams in the feature set. Adjust the `ngram_range` parameter in either CountVectorizer or TfidfVectorizer and observe the impact on the model's performance.

**Submission Instructions:**
- Submit your solution as a Jupyter Notebook (.IPynb file), as well as a link to your Google Colab notebook. Make sure that your Colab notebook is shared with "anyone with link".
- Your notebook should include sections for each feature engineering strategy, clearly marked with comments or Markdown cells.
- Each section should include the implementation of the feature extraction technique, model training, and evaluation.
- Use accuracy, precision, recall, and F1 score as your evaluation metrics.
- Include a summary section at the end of the notebook comparing the performance of the different feature engineering strategies.

**Evaluation Metrics:**
- Your assignment will be auto-graded based on the following metrics: accuracy, precision, recall, and F1 score. Ensure your notebook outputs these metrics for each model variant in a consistent and easily extractable format.

**Note:** Ensure that each cell in your Jupyter Notebook that outputs the required metrics for auto-grading does so in a clear and consistent format. For instance, consider printing the metrics in a dictionary format:

```python
print({"CountVectorizer -- Accuracy": accuracy, "CountVectorizer -- Precision": precision, "CountVectorizer -- Recall": recall, "CountVectorizer -- F1 Score": f1})

print({"TFIDF -- Accuracy": accuracy, "TFIDF -- Precision": precision, "TFIDF -- Recall": recall, "TFIDF -- F1 Score": f1})

print({"NGRAM -- Accuracy": accuracy, "NGRAM -- Precision": precision, "NGRAM -- Recall": recall, "NGRAM -- F1 Score": f1})
```

This structure will help streamline the auto-grading process, ensuring that your submission can be evaluated efficiently and accurately.

**Skeleton Code for the Assignment:**
"""

import os

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Load the dataset
df = pd.read_csv('/content/drive/MyDrive/DL/SMS-Dataset.csv')

df

# Split the dataset

# Baseline: CountVectorizer
# vectorizer = CountVectorizer()
# Implement your CountVectorizer feature extraction, model training, and evaluation here

# TF-IDF Transformation
# tfidf_vectorizer = TfidfVectorizer()
# Implement your TfidfVectorizer feature extraction, model training, and evaluation here

# N-grams
# ngram_vectorizer = CountVectorizer(ngram_range=(1, 2)) # Example for using bi-grams
# Implement your N-gram feature extraction, model training, and evaluation here

# Summary
# Compare the performance metrics of the different feature engineering strategies and summarize your findings.
# Import necessary libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Load the dataset (replace 'path_to_dataset.csv' with the actual path)
# df = pd.read_csv('path_to_dataset.csv')

# Assuming the dataset has 'text' and 'label' columns
X = df['Message']
y = df['Category']
# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Baseline: CountVectorizer
print("CountVectorizer:")
count_vectorizer = CountVectorizer()
X_train_count = count_vectorizer.fit_transform(X_train)
X_test_count = count_vectorizer.transform(X_test)

# Model training
model_count = LogisticRegression()
model_count.fit(X_train_count, y_train)


# Model evaluation for CountVectorizer
y_pred_count = model_count.predict(X_test_count)
accuracy_count = accuracy_score(y_test, y_pred_count)
precision_count = precision_score(y_test, y_pred_count, pos_label='spam')
recall_count = recall_score(y_test, y_pred_count, pos_label='spam')
f1_count = f1_score(y_test, y_pred_count, pos_label='spam')

print({"CountVectorizer -- Accuracy": accuracy_count,
       "CountVectorizer -- Precision": precision_count,
       "CountVectorizer -- Recall": recall_count,
       "CountVectorizer -- F1 Score": f1_count})


# TF-IDF Transformation
print("\nTF-IDF:")
tfidf_vectorizer = TfidfVectorizer()
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

# Model training
model_tfidf = LogisticRegression()
model_tfidf.fit(X_train_tfidf, y_train)

# Model evaluation for TF-IDF
y_pred_tfidf = model_tfidf.predict(X_test_tfidf)
accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)
precision_tfidf = precision_score(y_test, y_pred_tfidf, pos_label='spam')
recall_tfidf = recall_score(y_test, y_pred_tfidf, pos_label='spam')
f1_tfidf = f1_score(y_test, y_pred_tfidf, pos_label='spam')

print({"TFIDF -- Accuracy": accuracy_tfidf,
       "TFIDF -- Precision": precision_tfidf,
       "TFIDF -- Recall": recall_tfidf,
       "TFIDF -- F1 Score": f1_tfidf})


# N-grams
print("\nN-grams:")
ngram_vectorizer = CountVectorizer(ngram_range=(1, 2))  # Example for using bi-grams
X_train_ngram = ngram_vectorizer.fit_transform(X_train)
X_test_ngram = ngram_vectorizer.transform(X_test)

# Model training
model_ngram = LogisticRegression()
model_ngram.fit(X_train_ngram, y_train)

# Model evaluation for N-grams
y_pred_ngram = model_ngram.predict(X_test_ngram)
accuracy_ngram = accuracy_score(y_test, y_pred_ngram)
precision_ngram = precision_score(y_test, y_pred_ngram, pos_label='spam')
recall_ngram = recall_score(y_test, y_pred_ngram, pos_label='spam')
f1_ngram = f1_score(y_test, y_pred_ngram, pos_label='spam')

print({"NGRAM -- Accuracy": accuracy_ngram,
       "NGRAM -- Precision": precision_ngram,
       "NGRAM -- Recall": recall_ngram,
       "NGRAM -- F1 Score": f1_ngram})


# Summary
print("\nSummary:")
print("CountVectorizer Metrics:", {"Accuracy": accuracy_count, "Precision": precision_count, "Recall": recall_count, "F1 Score": f1_count})
print("TF-IDF Metrics:", {"Accuracy": accuracy_tfidf, "Precision": precision_tfidf, "Recall": recall_tfidf, "F1 Score": f1_tfidf})
print("N-gram Metrics:", {"Accuracy": accuracy_ngram, "Precision": precision_ngram, "Recall": recall_ngram, "F1 Score": f1_ngram})